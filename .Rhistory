# analyse participant level data
# load the relevant libraries
x<-c("tidyverse","car", "nlme", "lme4", "ez", "dplyr", "ggplot2", "knitr","stringr","nortest","gridExtra","png","R.matlab","lmerTest","simpleboot")
lapply(x, function(x) {if (!require(x, character.only=T)) {install.packages(x);require(x)}})
# clear all
rm(list=ls(all=TRUE))
# which dataset?
dataset2use = 'bigDots'; nSub = 80;
# dataset2use = 'CD'; nSub = 17;
filedir = str_c('E:/Monash/', dataset2use, '/data/population/')
figDir  = str_c(filedir, 'fig/R/' )
dir.create(figDir, showWarnings = TRUE)
# load useful functions ---------------------------------------------------
wddir   = str_c('C:/Jochem/repositories/2018_Monash/')
setwd(wddir)
source("summarySE.R")
# a few settings defined in Matlab, goes in the filename that will be loaded
CSD = 0
nChanAlpha = 3
# what is the number of bins etc?
nside           = 1;
nbin            = 5;
bintype         = 'equal';
# which sorting?
bin2use         = 'pupil_lp_baseline_regress_iti_side'
# bin2use         = 'pupil_bp_baseline_regress_iti_side'
# bin2use         = 'pupil_lp_RT_neg200_200_regress_bl_iti_side';
# bin2use         = 'pupil_bp_RT_neg200_200_regress_bl_iti_side';
# bin2use         = 'pretarget_alpha';
# bin2use         = 'N2i_amplitude_regress_iti_side'
# ------------------------------------------------------------------------
# look at data averaged for each participannt
# ------------------------------------------------------------------------
# load participant level data
filename = str_c('participant_level_side(',nside ,')_bin(', nbin, ')_', bin2use ,
'_equal_CSD(', CSD, ')_','chAlpha(', nChanAlpha, ')_final' )
data_p_level = read_csv(str_c(filedir, filename,'.csv'))
data_p_level$Subject <- factor(data_p_level$Subject)
data_p_level$Side <- factor(data_p_level$Side)
data_p_level$Bin <- factor(data_p_level$Bin,labels=c("1", "2", "3", "4", "5"))
#  ------------------------------------------------------------------------
## check number of trials in each condition
sum_trials <- summarySE(data_p_level, measurevar="nTrial", groupvars=c("Bin","Side"))
sum_trials <- data.frame(sum_trials)
tt <- ttheme_default(colhead=list(fg_params = list(parse=TRUE)))
tbl <- tableGrob(sum_trials, rows=NULL, theme=tt)
png(str_c(figDir,'nTrials', bin2use, '.png'))
grid.arrange(tbl)
dev.off()
#  ------------------------------------------------------------------------
data_p_level$Bin <- as.numeric(data_p_level$Bin) # for polynomial contrasts to be set
data_p_level <- within(data_p_level, polyBin <- poly(Bin,2)) # define orthogonal polynomial
# our model has a random intercept for each subject (repeated measrures analysis)
model.Intercept     <- lme4::lmer(RT ~ 1 +
(1|Subject),
data = data_p_level, na.action = na.omit, REML=FALSE) # baseline model to compare the effect of bin to.
model.bin       <- update(model.Intercept, .~. + polyBin[, 1]) # test linear polynomial
model.binQ      <- update(model.bin, .~. + polyBin[, 2])# test quadratic polynomial
# model.bin       <- update(model.Intercept, .~. + Bin) # test linear polynomial, not orthogonal!!
# model.binQ      <- update(model.bin, .~. + I(Bin^2))# test linear polynomial, not orthogonal!!
anova(model.Intercept, model.bin, model.binQ) #compare likelihood of models
library(broom)
summary(model.binQ)
kable(tidy(model.binQ),digits = 3)
library(MuMIn)
r.squaredGLMM(model.binQ)
# see https://jonlefcheck.net/2013/03/13/r2-for-linear-mixed-effects-models/ for an explanation of marginal and conditional R2
library(piecewiseSEM)
rsquared(list(model.Intercept,model.binQ))
#
# exclude some variables
all.dependent.variables <- data_p_level %>%
dplyr::select(-one_of("Subject"), -one_of("Side"), -one_of("Bin"), -one_of("polyBin"),
-one_of("nTrial"),
-one_of("pupil_bl_lp"), -one_of("pupil_bl_bp")) %>%
names()
fitlist_lme4 <- lapply(all.dependent.variables, function(i) {
eval(parse(text=
paste0('
model.baseline     <- lme4::lmer(', i, ' ~ (1|Subject), data = data_p_level, na.action = na.omit, REML=FALSE) # baseline model to compare the effect of bin to
model.bin          <- update(model.baseline, .~. + polyBin[, 1]) # test model with Bin, linear
model.binQ         <- update(model.bin, .~. + polyBin[, 2]) # test model with Bin, quadratic
stat <- anova(model.baseline, model.bin,model.binQ)
# model.bin <- as(model.bin,"merModLmerTest") # use the lmerTest package to obtain a p-value for the coefficients
trend <- coef(summary(model.binQ))
fit_Y_L <- predict(model.bin)
mat_fitL <- matrix(NA, nrow =1, ncol = (nSub*nbin))
mat_fitL[as.numeric(names(fit_Y_L))] <-  unname(fit_Y_L)
# mat_fitL <- matrix(mat_fitL, nrow = nSub, byrow = FALSE)
fit_Y_Q <- predict(model.binQ)
mat_fitQ <- matrix(NA, nrow =1, ncol = (nSub*nbin))
mat_fitQ[as.numeric(names(fit_Y_Q))] <-  unname(fit_Y_Q)
# mat_fitQ <- matrix(mat_fitQ, nrow = nSub, byrow = FALSE)
list(stat=stat, trend=trend, fitL=mat_fitL, fitQ=mat_fitQ)
')
))
})
# here we can only use the subjects that have complete data, so we delete subjects with NA values in CPP_onset
probeColumns = c('CPP_onset')
reduced_data <- data_p_level %>%
dplyr::select( 1:3, one_of("RT"), one_of("RT_CV"),
one_of("alpha"),
one_of("N2c_latency"), one_of("N2c_amplitude"), one_of("N2i_latency"), one_of("N2i_amplitude"),
one_of("CPP_onset"), one_of("CPP_slope2"), one_of("CPPr_amplitude"), one_of("CPP_ITPC"),
one_of("preRespBeta_base"), one_of("preRespBeta_slope"))
reduced_data <- plyr::ddply(reduced_data, "Subject",
function(df)if(any(is.na(df[, probeColumns]))) NULL else df)
reduced_data$Bin <- as.numeric(reduced_data$Bin)
# test the sequential addition of each variable and see which ones explain a significant part of the data
model.baseline    <- lme4::lmer(RT ~ Bin + (Bin|Subject), data = reduced_data, na.action = na.omit, REML=FALSE) # baseline model to compare the effect of bin to
model.alpha             <- update(model.baseline, .~. + alpha)#
model.N2c_lat           <- update(model.alpha, .~. + N2c_latency)#
model.N2c_amp           <- update(model.N2c_lat, .~. + N2c_amplitude)#
model.N2i_lat           <- update(model.N2c_amp, .~. + N2i_latency)#
model.N2i_amp           <- update(model.N2i_lat, .~. + N2i_amplitude)#
model.CPP_onset         <- update(model.N2i_amp, .~. + CPP_onset)#
model.CPP_slope         <- update(model.CPP_onset, .~. + CPP_slope2)#
model.CPP_ampl          <- update(model.CPP_slope, .~. + CPPr_amplitude)#
model.CPP_ITPC          <- update(model.CPP_ampl, .~. + CPP_ITPC)#
model.preRespBeta_slope <- update(model.CPP_ITPC, .~. + preRespBeta_slope)#
model.preRespBeta       <- update(model.preRespBeta_slope, .~. + preRespBeta_base)#
# check correlation between variables
corrmat <- cov2cor(vcov(model.preRespBeta))
corrmat <- corrmat[2:nrow(corrmat),2:ncol(corrmat)]
idx <- (abs(corrmat)>0.25 & abs(corrmat)<1)
t(t(apply(idx, 1, function(u) paste( names(which(u)), collapse=", " ))))
corrmat
anova(model.baseline, model.alpha, model.N2c_lat, model.N2c_amp, model.N2i_lat, model.N2i_amp, model.CPP_onset, model.CPP_slope, model.CPP_ampl, model.CPP_ITPC, model.preRespBeta_slope, model.preRespBeta)
model.full_RT    <- lmerTest::lmer(RT ~ Bin + N2c_amplitude + CPP_onset + CPP_slope2 + CPP_ITPC + (Bin|Subject), data = reduced_data, na.action = na.omit, REML=FALSE) # baseline model to compare the effect of bin to
summary(model.full_RT)
kable(tidy(model.full_RT),digits = 3)
# forward/backward stepwise model excluded CPP onset as a predictor adding any unique information, so we run the full model again without CPP onset
model.full_baseline    <- lmerTest::lmer(RT ~ Bin + (Bin|Subject), data = reduced_data, na.action = na.omit, REML=FALSE) # baseline model to compare the effect of bin to
model.full_pred    <- update(model.full_baseline, .~. + N2c_amplitude + CPP_ITPC) # baseline model to compare the effect of bin to
anova(model.full_baseline, model.full_pred)
summary(model.full_pred)
summary(model.full_RT)
model.full_baseline    <- lmerTest::lmer(RT ~ (1|Subject), data = reduced_data, na.action = na.omit, REML=FALSE) # baseline model to compare the effect of bin to
model.full_pred    <- update(model.full_baseline, .~. + (1|Bin)) # baseline model to compare the effect of bin to
anova(model.full_baseline, model.full_pred)
summary(model.full_pred)
